{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AudioDataPreparation.ipynb",
      "provenance": [],
      "mount_file_id": "1Ajmv3ghyyB7uL4I7fSKwF-hbTUTlLarl",
      "authorship_tag": "ABX9TyP5vjHYQ2dF9kOvGIQjlTUI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akash5169/Deep-Learning/blob/main/Audio-Classification/AudioDataPreparation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "import librosa\n",
        "import math\n",
        "import json"
      ],
      "metadata": {
        "id": "ONplR88kxHAu"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMwsMuYsyEPK",
        "outputId": "c847887a-c999-45eb-dca8-bb662de22e22"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_PATH=\"/content/drive/MyDrive/Data/genres_original\"\n",
        "JSON_PATH=\"data.json\"\n",
        "SAMPLE_RATE=22050\n",
        "DURATION=30\n",
        "SAMPLES_PER_TRACK=SAMPLE_RATE* DURATION"
      ],
      "metadata": {
        "id": "gY-cbwxLz9p9"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ijt5Fk4ehl2W"
      },
      "outputs": [],
      "source": [
        "def save_mfcc(dataset_path, json_path, n_mfcc=13, n_fft=2048, hop_length=512, num_segments=5):\n",
        "  #dictionary to store data\n",
        "  data= {\n",
        "      \"mapping\":[],\n",
        "      \"mfcc\":[],\n",
        "      \"lables\":[]\n",
        "  }\n",
        "\n",
        "  num_samples_per_segment= (SAMPLES_PER_TRACK/num_segments)\n",
        "  expected_num_mfcc_vectors_per_segment = math.ceil(num_samples_per_segment/hop_length)\n",
        "\n",
        "  #loop through all generes\n",
        "  for i , (dirpath, dirnames,filenames) in enumerate(os.walk(dataset_path)):\n",
        "    \n",
        "    #ensure that we are not at the root levele\n",
        "    if dirpath is not dataset_path:\n",
        "      \n",
        "\n",
        "      dirpath_components=dirpath.split(\"/\")\n",
        "      semantic_label=dirpath_components[-1]\n",
        "      data[\"mapping\"].append(semantic_label)\n",
        "\n",
        "      print(\"\\n Processing {}\".format(semantic_label))\n",
        "\n",
        "      #process files for specific genere\n",
        "      for f in filenames:\n",
        "        #load audio file\n",
        "        file_path=os.path.join(dirpath,f)\n",
        "        signal,sr=librosa.load(file_path, sr=SAMPLE_RATE)\n",
        "\n",
        "        #process segments extracting mfcc and storing data\n",
        "        for s in range(num_segments):\n",
        "          start_sample= num_samples_per_segment* s\n",
        "          finish_sample= start_sample+ num_samples_per_segment\n",
        "\n",
        "          start_sample=int(start_sample)\n",
        "          finish_sample=int(finish_sample)\n",
        "          #extract MFCC  \n",
        "          mfcc=librosa.feature.mfcc(signal[start_sample:finish_sample], sr=sr, n_fft=n_fft, n_mfcc=n_mfcc, hop_length=hop_length)\n",
        "          mfcc=mfcc.T\n",
        "\n",
        "          #store mfcc for segment if it has the expected length\n",
        "          if len(mfcc) == expected_num_mfcc_vectors_per_segment:\n",
        "            data[\"mfcc\"].append(mfcc.tolist())\n",
        "            data[\"lables\"].append(i-1)\n",
        "            print(\"{}, segment:{}\".format(file_path,s+1))\n",
        "    \n",
        "  with open(JSON_PATH,\"w\") as fp:\n",
        "    json.dump(data,fp,indent=4)          \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ ==\"__main__\":\n",
        "  save_mfcc(DATASET_PATH, JSON_PATH,num_segments=10)"
      ],
      "metadata": {
        "id": "hmS3qJG2HQoz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}